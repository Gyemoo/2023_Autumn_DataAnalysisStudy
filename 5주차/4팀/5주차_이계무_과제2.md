# 5주차과제
## 4.3 데이터 병합 후 처리
### 4.3.1 합친 데이터에서 중복 행 확인 및 삭제하기
```python
data_d = pd.DataFrame({
'패션아이템': ['팬츠', '팬츠', '자켓', '자켓', '자켓'],
'스타일': ['캐주얼', '캐주얼', '캐주얼', '비즈니스룩', '비즈니스룩'],
'선호도(5점 만점)': [4, 4, 3.5, 4.2, 2.7]
})
data_d.duplicated(keep='first')
```
- 데이터를 합쳤을 경우 중복되는 데이터가 있을 수 있다.
- 이때는 duplicated 함수를 사용하여 확인할 수 있다.
- 함수의 매개변수 keep에는 'first','last',False를 전달할 수 있다.
- subset 매개변수에는 특정 컬럼만 제한하여 중복을 체크할 수 있다.
```python
data_d.drop_duplicates()
```
- drop_duplicates함수를 이용하여 중복된 행을 지워준다.

### 4.3.2 2개 데이터를 비교하여 다른 부분 파악하기
```python
data_c.compare(data_c_2)
패션아이템 평점
self other self other
0 팬츠 스커트 NaN NaN
2 NaN NaN 3.0 4.0
```
- compare 함수를 이용하여 동일한 길이의 두 데이터를 비교할 수 있다.
- 결과값은 본인쪽의 데이터는 self, 비교대상의 데이터는 other, 값이 동일할 경우 NaN으로 표시된다.


```python
data_e_2[data_e.eq(data_e_2).all(axis=l) == False]
```
- 길이가 다른 데이터의 경우 값이 다른 데이터만 찾을 수 있는 방식이다.
- 길이와 인덱스가 모두 다를 경우, merge 함수를 이용하여 병합한 후, NaN이 생기는 행은 동일하지 않은 행인 것을 알 수 있다.

```python
패션아이템 평점_2차 평점
0 팬츠 3.0 3.0
1 모자 6.0 NaN
2 자켓 7.0 7.0
3 패딩 6.0 NaN
4 스카프 7.0 NaN
5 장갑 3.0 NaN
6 스커트 5.0 5.0
```

## 5.1 그룹 연산의 이해
### 5.1.1 groupby 연산 기초

```python
diamonds = sns.load_dataset('diamonds')
grouped = diamonds['price'].groupby(diamonds['clarity'])
grouped.mean()
```
- clarity를 기준으로 price를 groupby해준다.
- groupby한 데이터는 그대로 시각화할 수는 없고, 각종 연산에 사용할 수 있는 상태가 된다.

```python
diamonds.groupby('cut')['price'].mean()
diamonds.groupby('color')['carat'].mean()
```
- cut 컬럼을 기준으로 price를 구하고, color 커럼을 기준으로 carat을 구하였다.

### 5.1.2 데이터 집계
![image](https://github.com/sejongsmarcle/2023_Autumn_DataAnalysisStudy/assets/127960949/5cf5fc46-1c97-44c3-83bc-e6914511dc08)

- groupby함수에 여러 통계 관련 함수를 적용할 수 있다.

```python
tips_byday_percent.agg(['mean', 'std', 'sum'])

mean std sum
Thur Yes 0.163863 0.039389 2.785676
No 0160298 0 038774 7.213414
Fri Yes 0.174783 0.051293 2 621746
No 0.151650 0.028123 0.606602
Sat Yes 0.147906 0 061375 6.212055
No 0.158048 0.039767 7 112145
Sun Yes 0.187250 0.154134 3.557756
No 0.160113 0.042347 9.126438
```
agg함수를 통해 컬럼에 따라 다른 함수를 사용해서 집계하거나, 여러 함수를 동시에 적용할 수 있다.

```python
function_tuple = [('팁_평균', 'mean'), ('팁_표준편차', 'std')]
tips_byday['tip_percent', 'total_bill'].agg(function_tuple)

tip_percent total_bill
day smoker
팁_평균 팁_표준편차 팁_평균 팁_표준편차
Thur Yes 0.163863 0 039389 19.190588 8.355149
No 0.160298 0 038774 17.113111 7 721728
Fri Yes 0.174783 0.051293 16.813333 9.086388
No 0.151650 0 028123 18 420000 5 059282
Sat Yes 0.147906 0 061375 21.276667 10069138
No 0.158048 0 039767 19.661778 8.939181
Sun Yes 0.187250 0.154134 24.120000 10.442511
No 0160113 0 042347 20.506667 8.130189
```
- 튜플, 딕셔너리 등을 활용하여 여러 컬럼에 각각 다른 함수를 적용시킬 수도 있다.
- as_index=False로 지정하면 다중형 인덱스가 아닌 일반적인 형태로 데이터를 반환받을 수 있다.

### 5.1.3 groupby-apply 작업의 개념
```python
def top(data, n=5, column='body_mass_g'):
return data.sort_values(by=column)[-n:]

penguins.groupby('sex').apply(top)

```
- groupby처리 후, 사용자가 정의한 함수를 적용할 수 있다. 위 함수의 실행 결과 성별에 따른 tail 5개 행들을 반환한다.

```python
penguins.groupby('sex')['body_mass_g', 'flipper_length_mm'].apply(lambda x: x.describe())
body_mass_g flipper_length_mm
sex
Female count 165.000000 165.000000
mean 3862.272727 197 363636
std 666 172050 12.500776
min 2700.000000 172.000000
25% 3350.000000 187.000000
50% 3650 000000 193.000000
75% 4550.000000 210.000000
max 5200.000000 222.000000
Male count 168.000000 168 000000
mean 4545.684524 204.505952
std 787.628884 14.547876
min 3250.000000 178.000000
25% 3900 000000 193.000000
50% 4300.000000 200.500000
75% 5312 500000 219.000000
max 6300.000000 231.000000
```
- describe() 값과, lambda를 apply함수를 통해 적용시킬 수 있다.

```python
penguins['body_mass_g_bin'] = pd.cut(penguins['body_mass_g’], bins=5)
penguins.head()
species island bill_length_mm flipperjwgth_mm body_mass_g sex body mass g bin
0 Adelie Tbrgersen 39.1 187 181.0 3750.0 Male (3420.0, 4140.0]
1 Adelie Tbrgersen 39.5 17.4 186.0 3800.0 Female (3420.0, 4140.이
2 Adelie Tbrgersen 40.3 18.0 195.0 3250.0 Female (2696.4, 3420.0]
4 Adelie Ibrgersen 36.7 19.3 193.0 3450.0 Female (3420.0, 4140.0]
5 Adelie Tbrgersen 39.3 20.6 190.0 3650.0 Male (3420 0, 4140.0]
```
- body_mass_g 값을 5개 구간으로 나누었다.

```python
penguins['flipper_length_mm_bin'] = penguins.groupby('body_mass_g_bin').flipper_
length_mm.apply(pd.cut, bins=2)
penguins.head()
```
- body_mass_g 와 flipper_length_mm 두가지 값을 활용하여 데이터를 10개 구간으로 나누었다.
