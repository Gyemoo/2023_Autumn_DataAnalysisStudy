# 4.3 데이터 병합 후 처리

## 4.3.1 합친 데이터에서 중복 행 확인 및 삭제하기   
중복 데이터 : 모든 컬럼의 값이 동일한 행   
중복 행 유무는 duplicated()함수로 처리   

```python

import pandas as pd

data_d = pd.DataFrame({
    '패션아이템' : ['팬츠', '팬츠', '자켓', '자켓', '자켓'],
    '스타일' : ['캐주얼', '캐주얼', '캐주얼', '비즈니스룩', '비즈니스룩'],
    '선호도(5점 만점)' : [4, 4, 3.5, 4.2, 2.7]
})

#keep 매개변수 : first / last / False(중복된 모든 행 표시)
#중복된 행이라면 bool값으로 반환 됨, 매개변수는 keep에 따라 위치 다르게 표시
data_d.duplicated(keep='first') 

#총 중복 행 개수 파악 가능, True/False 개수 세어줌
data_d.duplicated(keep=False).value_counts() 

#특정 컬럼만 제한해서 중복 데이터 파악 가능
data_d. duplicated(subset=['스타일']).value_counts()

#중복 행 삭제, 전체 기준 중복된 행 중 1개만 남기고 모두 삭제
data_d.drop_duplicates()

#특정 중복 행 삭제
data_d.drop_duplicates(subset=['패션아이템', '스타일'], keep='last')
```

## 4.3.2 2개 데이터 비교하여 다른 부분 파악

데이터 길이가 같은 경우
```python
import pandas as pd

data_c = pd.DataFrame({
    '패션아이템' : ['팬츠', '팬츠', '자켓', '자켓', '팬츠'],
    '선호도(5점 만점)' : [1.0, 2.0, 3.0, np.nan, 5.0],
    '평점' : [1.0, 2.0, 3.0, 4.0, 5.0]
})

#길이는 동일하지만 일부 값이 다른 데이터 C_2 생성
data_c_2 = data_c.copy()
data_c_2.loc[0, '패션아이템'] = '스커트'
data_c_2.loc[2, '평점'] = 4.0

#compare() 함수 사용, 각 행에서 차이가 있는 값만 보여줌, 차이 없다면 NaN 표시
data_c.compare(data_c_2)
#NaN 대신 원본 데이터가 보고 싶다면 keep_equal=True
data_c.compare(data_c_2, keep_equal=True)

#결과를 세로축으로 변경하여 관찰
data_c.compare(data_c_2, align_axis=0)

#전체 데이터 사이즈 유지한 채 비교하고 싶을 때, Keep_shape=True
data_c.compare(data_c_2, keep_shape=True)

```

데이터 길이가 다른 경우
```python
import pandas as pd

data_e = pd.DataFrame({
    '패션아이템' : ['팬츠', '스커트', '자켓', '티셔츠', '블라우스', '베스트'],
    '평점' : [3.0, 5.0, 7.0, 5.0, 2.0, 4.0]
})

data_e_2 = pd.DataFrame({
    '패션아이템' : ['팬츠', '스커트', '자켓', '티셔츠', '블라우스', '베스트', '패딩'],
    '평점' : [3.0, 6.0, 7.0, 3.0, 2.0, 4.0, 8.0]
})

#2개 데이터 중 가장 긴 길이를 기준으로 값 다른지 여부를 bool로 타입으로 반
#data_e.eq(data_e_2)

#행의 어느 위치에라도 다른 값이 있는 경우 True 반환
data_e.eq(data_e_2).all(axis=1)

#True에 해당하는 데이터만 필터
data_e_2[data_e.eq(data_e_2).all(axis=l) == False]
```

데이터 길이와 인덱스가 다른 데이터 비교   
>1. 인덱스 재설정<reset_index()> 후 eq() 함수 이용    
>2. merge 함수 이용 : 인덱스가 다른 데이터끼리 비교


```python
import pandas as pd
import numpy as np
import seaborn as sns

data_e = pd.DataFrame({
    '패션아이템' : ['팬츠', '스커트', '자켓', '티셔츠', '블라우스', '베스트'],
    '평점' : [3.0, 5.0, 7.0, 5.0, 2.0, 4.0]
})

data_e_3 = pd.DataFrame({
    '패션아이템' : ['팬츠', '모자', '자켓', '패딩', '스카프', '장갑', '스커트'],
    '평점' : [3.0, 6.0, 7.0, 6.0, 7.0, 3.0, 5.0]
})

#index가 다르면 값이 동일해도 동일하지 않다고 인식함
data_e_3[data_e.eq(data_e_3).all(axis=1)]

#data_e_3의 '평점 컬럼명을 변경 후, data_e와 left 방식으로 병합
#키로 활용할 컬럼을 left_on과 right_on에 입력
name_new = data_e_3.rename({'평점' : '평점_2차'}, axis=1)
data_merged = name_new.merge(data_e, how='left',
                             left_on=['패션아이템', '평점_2차'],
                             right_on=['패션아이템', '평점'])

#결측값 포함 데이터 함께 추출하기 위해 isna()함수 활용
data_e_3[data_merged['평점'].isna()]
```
# 5.1 그룹 연산의 이해

>분리-적용-결합
>>데이터를 하나의 키 기준으로 ‘분리’하고,   
분리한 각 그룹에 함수를 ‘적용’하여 새로운 값을 만들어내고,    
함수를 적용한 결과를 하나의 테이블로 ‘결합’하는 것

판다스의 그룹 연산은 groupby() 연산 활용, 데이터를 그룹별로 나누고 요약 및 집계 가능

```python
import pandas as pd
import seaborn as sns

#다이아몬드 데이터셋
diamonds = sns.load_dataset('diamonds')

#clarity 컬럼 기준으로 그룹화한 후, price 컬럼의 평균값 파
grouped = diamonds['price'].groupby(diamonds['clarity'])
#아래 코드까지 써주어야만 함, 바로 윗줄 코드는 그룹 연산 준비 작업
grouped.mean()

```
데이터가 그룹별로 수집되어 groupby ()에서 지정한 유일값이 
인덱스로 처리된 새로운 시리즈 객체가 생성

```python
#groupby()에 배열 형태로 전달
gtouped_2=diamond['price'].groupby([diamonds['color'], diamonds['clarity']]).mean()
```
#상위 인덱스가 clolor, 하위 인덱스가 clarity 2개 레벨로 구성된 인덱스 가진 평균 가격 데이터 반환

#하위 인덱스였던 clarity를 컬럼으로 변환
grouped_2.unstack()
```
```python
#cut 컬럼을 인덱스로 전체 데이터 평균 구하는 그룹 연산
diamonds.groupby(['cut']).mean()

범주형 컬럼인 color와 clarity를 제외한 모든 컬럼의 평균 가격을 확인할 수 있다. 그룹
연산에서 숫자가 아닌 값은 자동으로 결과에서 제외
```

```python
#size() 함수 적용시 결과를 시리즈로 반환,unstack() 함수와 결합 시 df 반환 가능
diamonds.groupby(['cut', 'clarity']).size().unstack()
```
```python
#cm 컬럼을 기준으로 price의 평균을 구하는 연산
diamonds.groupby('cut')['price'].mean()

#color를 기준으로 carat의 평균 구하는 연
diamonds.groupby('color')['carat'].mean()

#unstack() 함수 적용
diamonds.groupby(['cut', 'clarity'])['price'].mean().unstack()
```

## 5.1.2 데이터 집계
배열로부터 숫자 데이터를 만들어내는 것과 관련한 모든 작업

```python
#관련 함수
conunt() # 결측값을 제외한 값의 개수를 반환
sum() # 결측값을 제외한 값들의 합을 반환
mean() # 결측값을 제외한 값들의 평균을 반환
median() # 결측값을 제외한 값들의 산술적인 중앙값을 반환
std(), var() # 편향되지 않은 표준편차, 분산을 반환
min(), max() # 결측값을 제외한 최솟값. 최댓값을 반환
prod() # 결측값을 제외한 값들의 곱을 반환
first(), last() # 결측값을 제외한 첫 번째 값. 마지막 값을 반환
```
## 5.1.3 groupby-apply 작업의 개념


```python
import pandas as pd
import seaborn as sns

penguins = sns.load_dataset("penguins")
penguins = penguins.dropna() #결측값 제거

#그룹별 상위 5개의 body_mass_g 값 추출하는 함수
def top(data, n=5, column='body_mass_g'):
return data.sort_values(by=column)[-n:]

#n의 기본값은 5, 상위 n개 출력
top(penguins, n=8)

#성별을 구분한 뒤 각각 상위 5개 데이터를 반환
penguins.groupby('sex').apply(top)

#컬럼 2개 기준으로 함수 apply, 행 수는 1개만 출력, body_mass_g 컬럼 값 집계
penguins.groupby(['sex', 'species']).apply(top, n=i, column=’body_mass_g,)

#컬럼 2개 기준으로 함수 apply, 행 수는 1개만 출력, bill_length_mm 컬럼 값 집계
penguins. groupby ([' sex', ' species' ]). apply(top；, n=l, column=' bill_length_mm')
```

describe() 함수와 groupby()
```python
#특정 컬럼 기준으로 통계량 세분화해서 살펴보기 가능
penguins.groupby(’sex')['body_mass_g'].describe()

#unstack() 함수 이용하여 컬럼을 행으로 변환시켜서 확인 가능
penguins.groupby(‘sex’)['body_mass_g'].describe().unstack('sex')
```

describe() 함수와 apply 함수
```python
#이전 예제에서 apply에 lambda를 활용하여 백분위수까지 반환
penguins.groupby('sex')['body_mass_g', 'flipper_length_mm'].apply(lambda x: x.describeO)
```
특정 그룹 단위에 대한 버킷 분석
```python
#body_mass_g 변수를 5개 구간으로 나눈 값을 body_mass_g_bin이라는 새로운 컬럼에 생성
penguins['body_mass_g_bin'] = pd.cut(penguins['body.mass.g’], bins=5)

#body_mass_g_bin 컬럼의 구간값을 기준으로 flipper_length_mm의 값을 구간화
penguins['flipper_length_mm_bin'] = penguins.groupby('body_mass_g_bin').flipper_lengthjnm.apply(pd.cut, bins=2)

#flipper_length_mm_bin 컬럼의 10개 고윳값을 확인
penguins.flipper_length_mm_bin.value_counts()
```
island 컬럼 기준 ver.
```python

penguins['bill_length_inm_bin_by_island'] = penguins.groupby(’island').bill_length_mm.apply(pd.cut, bins=2)
penguins[['island', ’bill_length_inm'丄 'bill_length_mm_bin_by_island']].head(10)

#구간 나누기
penguins[['island', 'bill_length_mm', 'bill_length_inm_bin_by_island']].tail()
```
