# 3.6 람다를 활용한 데이터 
map() :단일 컬럼, 즉 시리즈에만 적용 가능   
apply() :단일 또는 복수 컬럼, 즉 데이터프레임과 시리즈 모두에 적용 가능   
applymap() : 복수 컬럼, 즉 데이터프레임에만 적용 가능   

## 3.6.1 단일 컬럼에 람다 적용 예

하나의 변수의 고윳값을 딕셔너리 타입으로 지정
한 값으로 매칭해서 변경할 때 많이 사용

``` python
import pandas as pd
titanic = pd.read_csv('titanic.csv')

def fare_to_int(fare):
  to_int = int(fare + fare / 1000)
  return to_int

#여기부터 모두 같은 결과 등장
titanic['Fare'].map(fare_to_int).head() 
titanic['Fare_int'] = titanic['Fare'].map(lambda x: int(x + x / 1000))
titanic['Fare_int'] = titanic['Fare'].apply(lambda x: int(x + x / 1000))

#if. else 구문 응용
titanic['Age'].apply(lambda x: 'Adult' if x >= 18 else 'Child')
#Age가 18이상이면 Adult로 아니면 Child로 바꾸기
```

## 3.6.2 데이터프레임에 람다 적용 예

```python
import pandas as pd
titanic = pd.read_csv('titanic.csv')

def fare_to_int(fare):
  to_int = int(fare + fare / 1000)
  return to_int

#아래 2개 똑같은 결과 
titanic[['SibSp', 'Parch']].apply(lambda x: x['SibSp'] + x['Parch'], axis=1)
titanic[['SibSp', 'Parch']].apply(lambda x: x.sum(), axis=1)

```

```python
import seaborn as sns
iris = sns.load_dataset('iris')
iris_no_scepices = iris[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]

#모든 값에 10 곱하기
iris_no_scepices.applymap(lambda x: x*10).head()

```

# 4.1 데이터 병합
```python
import numpy as np
import pandas as pd
```

## 4.1.1 데이터를 위아래로 연결하기
contatct()
append()

```python
menu_1 = pd.Series(['파스타', '라멘', '냉면'], index=[1, 2, 3])
menu_2 = pd.Series(['돈가스', '피자', '치킨'], index=[4, 5, 6])

#순서대로 아래에 연결
pd.concat([menu_1, menu_2])
```

```python
#컬럼이 같은 경우
data_1 = pd.DataFrame({'음식명':['돈가스', '피자', '초밥', '치킨', '탕수육'],
                              '카테고리':['일식', '양식', '일식', '양식', '중식']})


data_2 = pd.DataFrame({'음식명':['갈비탕', '냉면', '짜장면', '파스타', '라멘'],
                              '카테고리':['한식', '한식', '중식', '양식', '일식']})

# 전달한 순서대로 이름 붙음,  index 정리 x ver.
pd.concat([data_1, data_2])
# index 어색하지 않게 바꾸기
pd.concat([data_1, data_2], ignore_index=True)
# 데이터 출처 밝히기
pd.concat([data_1, data_2], keys=['data_1에서 왔엉', 'data_2에서 왔슈'])
```

```python
#컬림이 다른 경우 : 결측값 존재
data_3=pd.DataFrame({'음식명': ['갈비탕', '냉면', '짜장면', '파스타', '라멘'],
                     '판매인기지역' : ['서울', '부산', '제주', '제주', '서울']})

#데이터1과 데이터 3 concat, join 기본값은 합집합(outer)
pd.concat([data_1, data_3], ignore_index=True)
# join inner (교집합이 부분만 얻기 → 같은 컬럼명만 모으기)
pd.concat([data_1, data_3], ignore_index=True, join ='inner')
```
```python
#append 사용
data_l.append(data_2, ignore_index=True)
# 컬럼 동일 X → concat처럼 outer로 연결

```

## 4.1.2 컬럼 기준으로 데이터 병합(좌우로 연결)하기

concat axis 지정 가능 → 공통 컬럼 없더라도 옆으로 붙이기 가능

```python
# axis = 1 : 옆으로 붙이기, 기본값은 axis = 0
pd.concat([data_1, data_2], axis=1)
```

merge() 이용    
: 공통 컬럼 기준으로 inner join(교집합)
```python

data_4 = pd.DataFrame({'음식명': ['돈가스', '피자', '초밥', '치킨', '탕수육', '갈비탕', '냉면', '짜장면', '파스타', '라멘'],
                       '카테고리' : ['일식', '양식', '일식', '양식', '중식', '한식', '한식', '중식', '양식', '일식']})

data_5 = pd.DataFrame({'음식명': ['탕수육', '짜장면', '돈가스', '치킨', '파스타', '갈비탕', '초밥'], 
                       '판매인기지역' : ['서울', '부산', '제주', '서울', '서울', '제주', '부산']})


#inner join
pd.merge(data_4, data_5)

#outer join
pd.merge(data_4, data_5, how='outer') #how = left/right/outer/inner

#data_6=data_4.merge(data_5)
```

특정 컬럼을 기준으로 데이터 병합하는 join

```python
#겹치는 프레임에 접미사 붙여서 지정
data_6.join(data_7, lsuffix='_left_key', rsuffix='_right_key')

# on = 합칠 때 기준이 되는 컬럼, df 유지시킬 인덱스 함게 지정
data_6.join(data_7.set_index('판매인기지역'), on = '판매인기지역')
```

## 4.1.3 key 컬럼에 값이 같은 데이터가 여러 개 있는 경우 데이터 병합하기

하나의 키에 중복되는 데이터가 있는 경우

```python
menu_price = pd.DataFrame(
    {
        '음식명' : ['돈가스', '돈가스', '파스타', '파스타', '파스타'],
        '가격' : [9000, 10000, 12000, 13000, 15000]
    }
)

menu_location = pd.DataFrame(
    {
        '음식명': ['돈가스', '파스타', '파스타', '피자', '피자'],
        '매장위치' : ['삼성동', '명동', '홍대입구', '이태원', '가로수길']
    }
)

# 교집합 내에서 만들어 질 수 있는 데이터 조합 탄생
pd.merge(menu_price, menu_location)
```

## 4.1.4  컬럼명이 동일하지만 key 컬럼이 되면 안 되는 경우 데이터 병합하기

```python
menu_data1=pd.DataFrame(
    {
        '음식명' : ['초밥', '초밥', '갈비탕', '짜장면', '짜장면'],
        '판매날짜' : ['2021-10-01', '2021-10-02', '2021-10-01', '2021-10-01', '2021-10-02'],
        '메모' : ['20000', '15000', '13000', '7000', '9000']
    }
)

menu_data2=pd.DataFrame(
    {
        '음식명' : ['초밥', '갈비탕', '짜장면'],
        '메모' : ['일식', '한식', '중']
    }
)

#메모_x : 먼저 쓴 거 , 메모_y : 나중에 쓴 거
a = menu_data2.merge(menu_data1, on='음식명')

```

## 4.1.5 서로 다른 key 컬럼을 가진 데이터 병합하기
매개변수 left_on과 right_on 사용해서 key 컬럼 명시 필요    
이것들은 양쪽 df에서 join할 컬럼 or index 이름 의미   


```python
menu_price3 = pd.DataFrame(
    {
        '음식명' : ['초밥', '초밥', '갈비탕', '짜장면'],
        '가격' : [20000, 15000, 13000, 7000]
    }
)

menu_score=pd.DataFrame(
    {
        '메뉴명' : ['초밥', '갈비탕', '갈비탕', '짜장면'],
        '단가' : [10000, 7000, 6000, 3000]
    }
)

# left_on : menu_price3 기준, right_on : menu_score 기준
pd.merge(menu_price3, menu_score, left_on = '음식명', right_on='메뉴명')

#기준 컬럼 하나 삭제하기 drop()
pd.merge(menu_price3, menu_score, left_on = '음식명', right_on='메뉴명').drop('메뉴명', axis=1)
```

## 4.1.6 인덱스 기준으로 데이터 병합하기

```python
menu_data3 = pd.DataFrame(
        [20000, 15000, 12000, 13000, 15000],
        index = ['초밥', '초밥', '갈비탕', '갈비탕', '갈비탕'], columns=['가격'])

menu_data4 = pd.DataFrame(
        [12000, 7000, 8000, 9000, 25000],
        index = ['갈비탕', '짜장면', '짜장면', '짜장면', '탕수육'], columns=['가격'])

#기존 라벨 index 사라진 채 가격만 결합된 프레임 반환
pd.merge(menu_data3, menu_data4, how='outer')

#기존 인덱스 살리기
pd.merge(menu_data3, menu_data4, how='outer', left_index=True, right_index=True)
```

## 4.1.7 인덱스가 겹치는 데이터를 병합할 때의 결측값 처리

```python
# 결측값이 있지만, 인덱스가 동일한 2개의 df

data_9 = pd.DataFrame(
    {
        '음식명' : ['돈가스', np.nan, '초밥', '치킨', np.nan],
        '카테고리' : ['일식', '양식', np.nan, '양식', '중식'],
        '판매인기지역' : [np.nan, '부산', '제주', '제주', '서울']
    }
)

data_10=pd.DataFrame(
    {
        '음식명' : [np.nan, '냉면', '초밥', '치킨', '탕수육'],
        '카테고리' : ['일식', np.nan, '한식', '양식', np.nan]
    }
)

#data_9 결측값을 data_10 값으로 채우기
data_9.combine_first(data_10)

#data_10에는 '판매인기지역' 컬럼 존재 X → data_9의 결측값 그대로 남게 됨
```

```python
#결측값을 numpy의 where()로 처리하기

data_a = pd.Series([51, np.nan, 260, np.nan, 182],
                   index = ['a', 'b', 'c', 'd', 'e'])

data_b=pd.Series(np.arange(len(data_a), dtype=np.float64),
                 index = ['a', 'b', 'c', 'd', 'e'])

data_b[-1] = np.nan

#where 함수 이용하여 data_a 변수에 array([ 51., 1., 260., 3., 182.]) 저장
data_a = np.where(pd.isnull(data_a), data_b, data_a)

#결측값 채우기
data_a = pd.Series(data_a)
```

# 4.2 데이터 재형성과 피벗
테이블 형식의 데이터는 다양한 방식과 기준으로 데이터를 재배치하거나 피벗하는 것이 가능

## 4.2.1 컬럼을 인덱스로 교환하기
stack()   
unstack()

```python
coffee_size_data = pd.DataFrame([[10, 28], [8, 22]],
                                index = ['스타벅스', '커피빈'],
                                columns=['테이블 수', '매장 규모(평)'])

#데이터의 컬럼을 인덱스로 만들기
coffee_size_data.stack()
#시리즈 타입의 긴 형태의 테이블로 변형된다

#원상태로 돌리기
coffee_size_data.stack().unstack()
```

## 4.2.2 데이터 피벗하기
데이터 피벗 : 데이터 재구성 가능

``` python
import numpy as np
import pandas as pd

data_stock = pd.read_csv('stock_data.csv')

#symbol 컬럼을 인덱스로 하여 날짜별 거래량 관찰을 위해 피벗
data_stock.pivot(index='symbol', columns='date', values = 'volume')

#2019년 3월 4일의 애플 거래량이 가장 높은 것을 알 수 있다. 

#날짜를 인덱스로, 기업명을 컬럼으로 만들어서 종가 보기
data_stock.pivot(index='date', columns='symbol', values = 'close')

#pivot_table() 활용해도 동일한 결과 나옴, 매개변수도 pivot()과 동일
pd.pivot_table(data_stock, values = 'close', index = 'date', columns = 'symbol')
```

## 4.2.3 넓은 형태의 데이터를 긴 형태로 재형성하기

pivot() 반대 melt()   
pivot() : 하나의 컬럼 기준으로 n개의 df 생성   
melt() : 하나의 컬럼 제외한 여러 개의 컬럼을 병합하여 긴 데이터 형성

```python
data_s = pd.DataFrame(
    {
        '음식명' : ['돈가스', '우동', '냉면'],
        '평점' : [4.3, 4.2, 4.6],
        '가격' : [10000, 9000, 12000],
        '위치' : ['삼성동', '명동', '을지로입구']
    }
)

# 음식명 제외 모든 컬럼은 variable로, 해당 값은 value에 저장
data_s.melt('음식명')

#부분컬럼 이용하기 [가격, 위치 ] 순으로 정렬되게끔 만들어줌
data_s.melt(id_vars=['음식명'], value_vars=['가격', '위치'], var_name='항목명', value_name='항목값')

#pivot() 이용해서 되돌리기
data_s.melt('음식명').pivot('음식명', 'variable', 'value')
```

## 4.2.4  복합 개체를 개별 개체로 분리하기

explode() 이용

```python
data_e = pd.DataFrame(
    {'재료' : [['밀가루', '설탕', '계란'], '밀가루', [], ['버터', '생크림']], 
     '시간' : 10,
     '방식' : [['굽기', '볶기'], np.nan, [], ['볶기', '섞기']]})

#재료 컬럼 분리
data_e.explode('재료')

#방식 추가 분리
data_e.explode('재료').explode('방식')
```

