넘파이 /  판다스를 이용해 데이터 다루기
================
!!! 이하 내용은 기본적으로 다음의 코드가 작성되었음을 기준으로 합니다.

    import numpy as n
    import pandas as p

# 1. 데이터 로드 및 저장
지금까지 우리가 써온 데이터를 생성하는 방법으로도 데이터 관련 활동을 진행할 순 있다.
하지만 실제로 데이터 분석을 진행하는 경우는 대개 외부 파일에서 데이터를 끌어다 쓰는 경우이기 때문에, 기존 데이터 생성 방식으로 하나하나 데이터를 옮기기엔 뭔가 엄청 비효율적이다.
그래서 우리는 판다스 내부의 데이터 로드 관련 함수들을 이용해 파일을 받고, 파일 내 데이터 타입을 알아서 추론해 사용 가능하게 해주는 방법을 사용한다.
+ 대표적으로 활용되는 파일은 csv 파일이다. 이러한 CSV 파일은 다음과 같은 형식으로 로드가 가능하다.
  만약, 변수 a에다 우리가 경로를 아는 어떤 파일에 있는 데이터를 넣고 싶다면 이렇게 하면 된다.

    a = p.read_csv('대충 파일의 경로')

  + 이 read.csv()를 좀 더 자세히 보면 파일이 아니라 파일이 있는 폴더까지만 들어가서 파일에 접근하는 방식으로 돌아간다. 따라서 지금 실행중인 코랩과 동일한 경로에 있는 파일이라면 굳이 경로를 다 입력하지 않고 파일명만 입력해도 돌아간다.
  + csv파일은 데이터 프레임 형식으로 나온다.
  + 굳이 변수에 넣을 필요 없다면 read_csv() 말고 read_table()을 써도 된다. 이때는 구분자를 쉼표로 설정하는 명령어 sep=','를 잊지 말자.
  + 참고로 컬럼명이 따로 지정되있지 않은 데이터를 가져오면 데이터의 첫줄이 컬럼명으로 들어가는 불상사가 일어난다. 이를 막기 위해선 뒤에 header=None을 붙여주자.
    + 아니면 컬럼명을 별도로 지정해주면 된다. 경로 뒤에 names=컬럼명들 로 지정해주면 된다.
  + 컬럼명을 안다면 특정 컬럼을 인덱스로 지정하는 것도 가능하다. 뒤에 index_col='컬럼명' 해주면 해당 컬럼명이 인덱스가 되어준다.
  + 특정 행을 빼고 불러오기할 수 있다. 뒤에 skiprows=빼버릴행 을 입력하면 그 행만 빠져서 나온다.
    + 다만 인덱스를 따로 설정하지 않았다면 뺸 상태에서 0 1 2 3... 이런식으로 붙는다. 즉 3행을 뺐을때 0 1 3 4... 로 나오는게 아니다. 물론 인덱스만 그런것이지 실제로 행은 잘 빠진다.
    + 이러한 방법은 데이터셋이 많을 때 일부만 빼와야 하는 상황에서 쓰기 좋다. 빼버릴 행 부분에 lambda 함수를 이용한 식을 넣는걸로 가능하다. 가령 전체 데이터의 반만 출력해야 하는 상황이면 이렇게 가능하다.

    p.read_csv('파일경로', skiprows = lambda a : a>0 and n.random.rand() > 0.5 )

  + 로드하다보면 간혹 값이 채워지지 않은 부분을 로드해야 할 때가 있다. 이를 결측값이라고 하며, 판다스 내에서는 NaN으로 표기된다.
    뭐가 결측값이고 뭐가 값인지 보려면 p.isnull(데이터)를 쓰면 된다. 여기서 True가 결측값이고 False가 값이다.
    + 참고로 NaN 말고 다른 값도 결측값으로 인식되게 해버릴 수 있다. read.csv()를 쓸 때 뒤에 na_values=['NaN', 그 외 결측값으로 만들어버리고 싶은 것들] 해버리면 원하는걸 결측값으로 바꿔버릴 수 있다.
+ 디폴트로 출력되는 컬럼과 로우는 각각 최대 20, 60이다. 이는 다음과 같은 방법으로 확인할 수 있다.

    p.get_option("display.max_columns")
    p.get_option("display.max_rows")

  + 여기서 최대 출력을 바꾸고 싶다면, 다음과 같은 방법을 쓰면 된다. 임의로 최대 컬럼 30, 최대 로우 90으로 변경해보겠다.

    p.set_options("display.max_columns", 30)
    p.set_option("display.max_rows", 90)

  + 참고로 set_option 말고도 options.display.max_로우아님컬럼 = 원하는값 의 방법으로도 변경이 된다.
-----------
# sp. seaborn라이브러리
잠깐 중요한 기능 중 하나인 seaborn 라이브러리에 대해 짚고 넘어가자.
시본 라이브러리는 여러 데이터셋 샘플을 제공하는 라이브러리이다.
대표적으로 우리가 학습에 쓰는 교재에 나온 'iris'나 'penguins'가 있다.

샘플 데이터셋을 불러오는 방법은 아래와 같은 코드를 통해 가능하다.

    import seaborn as s
    s.load_dataset('iris')

이러면 데이터셋 'iris'가 불러와진다.

-----------
+ 데이터를 다 가지고 놀았다면, 이제 저장을 해야 할 차례이다. 저장은 다음과 같은 방법으로 가능하다. 대충 k라는 이름의 데이터셋이 있다고 치면,

    k.to_csv('대충의 경로/파일이름.csv')

  이러면 원하는 파일 이름으로 저장이 된다.
  + 원하는 컬럼만 뽑아서 저장할 수도 있다. 뒤에다 columns=[원하는 컬럼명들] 입력하면 된다.
  + 인덱스를 생략할 수도 있다. 뒤에다 index=False 붙이면 된다.
  + 헤더를 스킵하거나 원하는 이름으로 바꿔 쓸 수도 있다. 뒤에다 header=[원하는 헤더 이름] 넣으면 헤더 이름이 바뀌고, 이름들 대신 False 넣으면 헤더 이름이 없어진다.
  + 참고로 to_csv()대신 to_excel()로 하면 엑셀로 저장된다.

# 2. 데이터 확인
데이터셋을 불러왔으면, 이제 데이터셋을 확인할 차례다. 편의상 우리는 k라는 데이터셋을 가지고 본다고 하자.
+ 데이터의 앞부분을 확인하려면 k.head()를 사용하면 된다. 디폴트로는 앞쪽부터 5개가 나오며, 괄호 안에 원하는 수를 넣으면 그 수만큼 앞에서부터 나온다.
+ 데이터의 뒷부분을 확인하려면 k.tail()을 사용하면 된다. 이쪽도 head()랑 사용법은 같다.
+ 데이터의 로우와 컬럼이 몇개씩 있는지 확인하려면 k.shape를 사용하면 된다. 여기서 앞쪽이 로우, 뒤쪽이 컬럼이다. 참고로 반환형은 튜플이다.
+ 데이터프레임 내 모든 값의 개수를 확인하려면 k.size를 사용하면 된다. 데이터프레임이 아니라 시리즈에 사용하면 행의 수를 반환해준다.
+ 참고로 로우만 확인하려면 len(k)만으로도 가능하다. 이건 데이터의 길이를 의미하기도 한다.
+ k.dtypes를 이용하면 각 컬럼의 데이터타입을 출력해준다.
  + 여기서도 리스트가 들어간다거나 하면 object타입이 되버린다.
  + 간혹 문자열도 object타입으로 인식할 때가 있다. 이러면 아래의 방법을 써서 바꿔줘도 된다.
+ 데이터 타입을 알아서 가장 적합한 타입으로 바꿔주는 엄청나게 편리한 함수가 있다. 찬양하라.

     k=k.convert_dtypes()

  물론 이것도 한계가 있다. 100% 정확한건 아니라는 것. 때문에 이하의 방법을 써서 몇개는 수동으로 바꿔야 할 수도 있다.
+ 데이터 타입을 수동으로 바꾸는 것도 가능하다. 다음과 같은 2가지 방법 중 하나를 골라 쓰면 된다.

    k=k.astype({'원하는컬럼1' : '원하는타입1'})#이건 여러개 이어서 쓸 수도 있다.
    k['원하는컬럼']=k['원하는컬럼'].astype('원하는타입')

  적당히 원하는걸 골라쓰자. 참고로 2번째 방법은 하나씩만 된다.
  + 결측값이 끼어있으면 에러가 난다. 여기에 뭔가 채워주던가, 그냥 결측값이 있는 행을 지워버리던가 하면 된다.
+ 시리즈는 안되고, 데이터프레임 한정으로 k.info()라는걸 쓸 수 있다. 여기서 확인 가능한 정보는 다음과 같다.
  + 인덱스의 범위
  + 컬럼 개수
  + 컬럼당 비null값 수
  + 메모리 사용량
  + dtype(자세히는 안나오고, 각 dtype당 몇개의 컬럼이 있는지 정도만 알려준다.)
+ 기술통계 정보를 확인할 수 있는 함수 k.describe()가 있다. 이건 데이터수, 평균, 표준편차, 최소, 최대, 25%, 50%, 75%를 보여준다.
  + 이를 이용해서 다음과 같은 함수들이 작동한다.
    + 데이터 수를 구하는 k.count()
    + 최댓값을 찾는 k.max()
    + 최솟값을 찾는 k.min()
    + 평균을 찾는 k.mean()
    + 표준편차를 찾는 k.std()
    + 데이터 총합을 구하는 k.sum()

# 3. 데이터프레임 컬럼 다루기
이하 내용도 k라는 데이터 프레임이 있다고 가정한다.
+ k.columns 를 사용하면 k의 컬럼들을 인덱스 형태로 쭉 출력한다.
+ 컬럼 하나를 지정해서 호출할 경우 k['컬럼이름']하면 된다. 아니면 k.컬럼이름 도 된다.
  + 2개 이상 호출하려면 리스트를 쓴다. k[['컬럼1', '컬럼2']]  이렇게. 아니면 아예 컬럼명 리스트를 변수 하나에 때려박고 그 변수이름을 넣어도 된다.
+ 컬럼을 생성할 수도 있다. 기존 컬럼 'a'의 데이터를 반갈죽한 양의 데이터를 담은 컬럼 'b'를 만드는 경우 아래와 같다.

    k['b']=k['a'] /2

  아쉽게도 컬럼 생성 시에는 k.a k.b 같이 쓸 수 없다.
  + k.assign(생성할 컬럼들) 을 이용하면 대량으로 컬럼들을 생성할 수 있다.
+ dtype이 동일한 컬럼들끼리 선택하려면 k.select_dtypes(include=['데이터타입']).columns를 사용하면 된다. 참고로 여기서도 string타입은 object로 취급된다.
  + 반대로 어떤 dtype만 빼고 싶으면 include 대신 exclude 쓰면 된다.
+ drop()을 써서 컬럼과 로우를 지울 수 있다.
  + 컬럼을 지우려면 k.drop('컬럼명', axis=1)을 쓴다.
  + 로우를 지우려면 k.drop('로우번호', axis=0)을 쓴다.
  + 여러개 지우려면 컬럼명이나 로우번호를 리스트로 쓰면 된다.
+ 컬럼명을 바꿀 수 있다. k.rename(columns={"기존이름" : "새이름"}) 으로 가능하다. 여러개 하려면 ,로 연장해서 쓰면 된다.
+ 컬럼 순서를 바꿀 수 있다. 컬럼명을 원하는대로 재입력하면 된다. 또는 k.columns[[원하는 순서 리스트]]를 이용해 이름 대신 순서로 바꿀 수 있다.
+ 데이터프레임을 y=-x대칭을 시킬 수 있다. k.transpose()하면 된다.

# 4. 데이터프레임 내 값 선택하기 : 데이터 인덱싱
데이터프레임을 쓰다 보면 일부 데이터만 뽑아야 할 때가 있다. 이럴 때 사용하는게 바로 인덱싱 기법이다. 주로 판다스 내 loc과 iloc을 쓴다.
이하 내용 역시 k라는 데이터프레임이 있다고 가정한다.
+ 인덱스가 문자인 경우 k.loc['인덱스명', 컬럼위치]로 찾을 수 있다.
  + 컬럼 위치 안쓰면 그 인덱스에 해당하는 전체 값이 나온다.
  + 2개 이상의 인덱스에 접근해야 한다면 인덱스명을 리스트형으로 넣으면 된다.
  + 연속되는 2개 이상의 인덱스에 접근해야 한다면 ['시작인덱스':'끝인덱스', 컬럼위치] 도 된다.
  + 떨어져있는 개별 인덱스면 리스트형으로 써야 한다.
+ 위치 기반으로 인덱싱하려면 k.iloc[로우, 컬럼] 으로 가능하다.
  + 여러개 하려면 로우 따로, 컬럼 따로 리스트 형식으로 만들어줘야 한다. 물론 두 리스트의 값의 수는 같으며, 앞부터 1:1로 매칭되어서 들ㅇ간다.
+ 컬럼을 인덱스로 만들 수 있다. k.set_index('컬럼명')하면 된다.
  + 다시 리셋하려면 k.reset_index()하면 된다.

인상깊은 코드와 활용법
-----------------
값에 따라 dtype을 자동으로 바꿔주는 convert_dtypes()가 가장 인상깊었다. dtype이 원하는대로 되지 않을때가 많고, 특히나 많은 양의 데이터를 다룰 땐 그럴 때가 더 많을 것 같았는데, 세부적인 오류는 있을 지언정 대부분의 데이터를 가장 적합한 타입으로 바꿔준다는 점이 정말 흥미로웠다.
그 외에는 데이터프레임의 여러 정보를 한번에 알려주는 info()도 흥미로웠다. 코딩과정에서 요긴하게 써먹을 수 있을 듯 하다.

느낀점
---------------
꽤나 다양하고 세세한 기능이 많아서 다루기 쉬우면서도 까다롭다는 느낌이 들었다. 집에 있는 주말 등을 이용해서 구글 코랩과 함께 좀 더 깊게 공부해봐야겠다는 생각이 들기도 했고, 이걸 이용해 다양한 것들을 만들어보며 사용법을 손에 익게 해야겠다고 느끼기도 했다.
