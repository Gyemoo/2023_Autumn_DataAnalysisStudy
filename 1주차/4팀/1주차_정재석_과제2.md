# 1주차 과제

## 2.3 데이터 로드와 저장
```python
df = pd.read_csv() // 파일 로드하기
read_table() // 함수를 통해서 눈으로 확인 가능
```
1. 컬럼명 항목의 유무에 따라 읽는 함수가 달라진다.
2. 특정 컬럼을 인덱스로 지정해서 읽을 수 있다.
3. 일부 행을 건너 뛰고 데이터를 읽을 수 있다. (데이터 처리시 더미데이터 처리시 편리할것같다.)
4. 칼럼의 최대 출력수 지정도 가능하다.
5. 데이터를 CSV파일로 저장 하는것도 가능하다. by) to_csv(경로)

## 2.4 데이터 확인 
```python
import pandas as od
import seaborn as sns
```
판다스와 시본 라이버리를 임포트한다
1. 데이터의 앞부분을 확인하고싶다면 df.head(갯수) 를 통해서 확인가능
2. 데이터의 끝부분을 확인하고싶다면 df.tail(갯수) 를 통해서 확인가능
3. 차원, 그리고 길이확인함수
   1) df.shape() 사용시 행/열 확인가능 ex) (344,7) 344행 7열
   2) 값갯수 확인 df.size를 통해서 셀 갯수 확인
   3) 행 갯수확인을 원할실 len() 을통해서 가능
4. 데이터 타입 확인
   1) 자동 데이터 타입 변경함수 convert_dtypes() 사용시 타입이 자동변경
   2) 수동 데이터 타입 변경 함수 {} 를 통해서 변경
5. df.describe()를 통해 확인 가능
6. 데이터 값관련 함수들
   1) df.count() 셀 수 확인
   2) df.max() 해당 데이터 기준 가장 큰 값
   3) df.min() 해당 데이터 기준 가장 작은 값
   4) df.mean() 평균값 계산
   5) df.std() 표준편차 계산
   6) df.sum() 데이터 합 구하기
      
## 2.5 데이터프레임의 컬럼 다루기 기술
1. 데이터 분석을 지속하다보면 컬럼의 생성과 삭제가 반복되어 파악이 어렵다 이때 df.columns를 통하여 컬럼을 확인할수있다.
2. 내가 필요로 하는 컬럼만 호출하는 방법은  df['컬럼명'] 이다.
3. 컬럼 생성은 기본적인 파이썬 문법과 유사하다.
4. 컬럼과 로우를 삭제할수있다.
   1) 컬럼1개 삭제는 df.drop('컬럼명')
   2) 컬럼2개 이상 삭제 df.drop(['컬럼1','컬럼2'....])
5. 컬럼 이름 변경하기 df.rename() 이요하여 변경
6. 컬럼 순서/위치 변경 또한 함수들을 통해 가능하다.

## 2.6 데이터 인덱싱
1. 인덱스가 문자형인 경우에는 loc 함수를 활용 하여 인덱싱을 진행한다.
   인덱스가 문자형이 아니라면 데이터셋을 다시 로드하고 transpose()를 사용하여 df를 준비한다.
2. loc 은 우라벨 위주 인덱싱 but iloc 함수는 위치 기반 정수 인덱싱 기법
   ```python
   df = sns.load_dataset('penguins')
   ```
3. 컬럼을 인덱스로 만들고 재정의하기
   데이터 분석을 하다 보면 데이터를 변형하는 과정 기존값이나 재정의해야한다.
   set_index()함수를 활용하여 인덱스로 만든다.

## 1주차 과제를 하며 느낀점
데이터 분석이라는 제목 그 자체에서도 느껴지듯 데이트의 형태를 변형하고 불필요한데이터는 처리하고 필요한 데이터만 읽고자하는 기법들이? 들어가있다.
생각보다 다양한 함수들이있어 이부분을 모두 암기를 해야하는것인지 아님 때에따라 구글에 검색을 하며 진행해야하는것인지 공부를 해나가며 어려움을 느꼈다.
점점 할수있는 공부는 많아지지만 그에 비교할 수 없는 속도로 알아야하는 정보의 양이 많아지는것같다. 중요한 공부가 어떤거고 좋은 공부방법이 무엇인지 에대한 생각을 다시하게되었다.
