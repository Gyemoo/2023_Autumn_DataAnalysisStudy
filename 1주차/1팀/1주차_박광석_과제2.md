# 2.3 데이터 로드와 저장
데이터를 처리한 후 파일을 저장하는 방법도 살펴보자.
## 2.3.1 데이터 로드
csv 파일을 기준으로 하여 로드하는 여러 가지 방법을 학습.
### CSV 파일 로드하기
read_csv()
```python
df = pd.read_csv('')
```
```python
pd.read_csv('', header=None)
```
header=None 을 쓰면 원본 데이터에 헤더가 없으니 데이터의 1행을 헤더로 만들지 말라고 요청.
### 특정 컬럼을 인덱스로 지정해서 로드하기
```python
col_names = ['컬럼1', '컬럼2', '컬럼3', '컬럼4', '컬럼5', '키워드']
pd.read_csv('', names=col_names, index_col='키워드')
```
키워드 컬럼이 인덱스로 지정됨.
### 일부 행을 건너뛰고 데이터 로드하기
일부 행을 건너뛰고 로드하기 : skiprows라는 매개변수를 활용.\
건너뛰어야 하는 행이 2개 이상이면 반드시 리스트 형태로 입력.\
```python
pd.read_csv('', skiprows=[1, 3]) # 이러면 인덱스 1, 3(2행과 4행)이 생략됨
```
대용량 데이터셋을 줄여서 로드할 때: 행 대신 람다 함수를 활용.
```python
pd.read_csv('', skiprows = lambda x : x > 0 and np.random.rand() > 0.5)
```
### NA(결측값)가 포함된 데이터 로드
```python
na_data = pd.read_csv('')
na_data
>>> 직접확인
pd.isnull(na_data)
>>> na_data의 NA 값이 True로 출력됨
# Null 과 NaN 외에도 step 컬럼의 one 과 two라는 값도 결측값으로 인식하게 하자.
na_data = pd.read_csv('', na_values=['Null', 'NaN', 'one', 'two'])
na_data
>>> 직접확인
```
### 인코딩 관련 에러 대응하기
UnicodeDecodeError : \
문자열이 깨진 에러 : encoding = cp949 또는 utf-8 또는 euc-kr 로 시도\
utf-8 로 했을 때 오류 ->  utf-8-sig 로 바꿔 시
### 판다스로 로드 가능한 파싱 함수 목록
P.108페이지 보기.
## 2.3.2 데이터프레임 출력 관련 설정
### 현재 출력 컬럼과 로우 수 확인하기
```python
pd.get_option("display.max_columns")
>>> 20
pd.get_option("display.max_rows")
>>> 60
```
### 최대 출력 컬럼 수 지정하기
... 으로 생략된 부분없이 모두 출력가능
```python
pd.read_csv('')
pd.set_option("display.max_columns", 30) # 컬럼을 30개로 지정
# 아래 코드로도 가능
pd.options.display.max_columns = 30
```
### 최대 츨력 로우 수 지정하기
```python
import seaborn as ns
iris = sns.load_dataset('iris')
pd.set_option("display.max_rows", 150)
iris
>>> 직접확인
```
### 데이터를 CSV 파일로 저장하기
```python
iris.to_csv('')
# 데이터셋의 5개의 컬럼 중 3개 컬럼만 선택하여 csv로 저장
iris.to_csv('', columns=['', '', ''])
# 헤더를 생략하려면 header=False 로 설정
```
### 데이터를 엑셀 파일로 저장하기
```python
iris.to_excel('')
```
# 2.4 데이터 확인
판다스와 시본 라이브러리 임포트하기
```python
import pandas as pd
import seaborn as sns
```
## 2.4.1 데이터의 처음과 끝부분 확인
```python
df = sns.load_dataset('penguins')
```
### 데이터 앞부분 확인하기
```python
df.head(10) # 10을 적으면 앞에 10개를 확인
```
### 데이터 끝부분 확인하기
```python
df.tail() # 안적으면 5개 확인
```
## 2.4.2 데이터 차원과 길이 확인
### 데이터 차원 확인하기
```python
df.shape
>>>(344, 7)
```
344개의 행(로우)과 7개의 열(컬럼)으로 구성
### 모든 값의 개수 확인하기
```python
df.size
>>>2408
```
### 데이터 길이 확인하기
```python
len(df)
>>>344
```
## 2.4.3 데이터 타입 확인과 변경
dtypes 함수를 데이터프레임에 사용하면 데이터의 모든 컬럼 이름과 해당 데이터 타입을 1라인씩 출력
```python
df.dtypes
>>>직접확인
```
object 타입은 복합적 형태
### 자동으로 데이터 타입 변경
convert_dtypes() 함수는 자동으로 데이터 타입을 추론하여 바꾼다.
```python
df = df.convert_dtypes()
df.dtypes
```
원래 object 였던것이 string으로 바뀐다.
### 수동으로 데이터 타입 변경하기
1. df = df.astype('컬럼명':'데이터 타입')
2. df = df. astype({'컬럼':'타입', '컬럼명':'타입'})
3. df['컬럼'] = df['컬럼'].astype('타입')
## 2.4.4 데이터프레임 요약 정보 확인
```python
df.info()
```
## 2.4.5 기술통계 확인
### 기술통계 정보 확인하기
```python
df = sns.load_dataset('penguins')
df.describe() # 괄호 안에 include = 'all' 을 넣으면 모든 컬럼을 다 보여준다.
# 만약 include=[object]로 하면 데이터 타입이 object 만 보여준다.
```
### 백분위수 구하기
#### 넘파이로 백분위수 구하기
```python
df = df.fillna(0) # na 값을 모두 0으로 바꿈
# percentile 함수 사용
point_5 = np.percentile(df['bill_depth_mm'], q=[0, 25, 50, 75, 100])
```
#### 판다스로 백분위수 구하기
```python
df.quantile([0, .25, .5, .75, 1.0])
```
### 데이터 수 파악하기
```python
df.count()
```
### 최댓값 찾기
```python
df.max()
```
### 최솟값 찾기
```python
df.min()
```
### 평균값 계산하기
```python
df.mean()
```
### 표준편차 계산하기
```python
df.std()
```
### 데이터 합계 구하기
```python
df.sum()
```
### 기술통계 시각화: 막대그래프, 히스토그램, 박스플롯
시본에서 합계를 표현할 때는 catplot()이라는 막대그래프 함수를 활용함
```python
sns.catplot(data=df, x="species", kind="count", palette="ch:.25)
```
y축에 숫자 타입 변수를 지정하여 그릴 수 있는 barplot 함수도 존재
```python
sns.catplot(data=df, x="species", y = "bill_length_mm", palette="ch:.25")
```
히스토그램은 histplot()을 사용
```python
sns.histplot(data=df, x="flipper_length_mm", color='')
```
박스플록은 boxplot()을 사용
```python
sns.boxplot(data=df, palette="mako")
```
## 2.4.6 고윳값 확인
unique() 함수사용
### 고윳값과 해당개수 동시에 확인하기
value_counts() 함수사용
# 2.5 데이터프레임의 컬럼을 다루는 테크닉
## 2.5.1 현재 컬럼 목록 확인하기
```python
df.columns
```
## 2.5.2 컬럼 호출하기
컬럼 1개를 호출하는 경우
```python
df['species']
df.species
```
둘 다 가능
## 2.5.3 새로운 컬럼 생성하기
### 단일 컬럼 생성하기
```python
df['bill_depth_cm'] = df['bill_depth_mm'] / 10 #bill_depth_cm 라는 컬럼 새로 생성
```
### 다중 컬럼 동시에 생성하기
```python
df.assign(
    bill_length_cm=df['']
    bill_depth_cm-df['']
)
```
## 2.5.4 동일한 데이터 타입의 컬럼만 선택하기
```python
df.select_dtypes(include=['데이터 타입']).columns
```
## 2.5.5 컬럼과 로우 삭제하기
```python
# 컬럼삭제하기
df.drop('컬럼명', axis=1) #axis 방향은 세로를 의미하는 1로 설정
# 로우 삭제하기
df.drop('인덱스 번호', axis=0) # axis 방향은 가로를 의미하는 0으로 설정
```
## 2.5.6 컬럼 이름 변경하기
```python
df.rename(columns={"species":"펭귄 종류"})
```
## 2.5.7 컬럼 순서/위치 변경
이 부분 이해못함 ㅠ
## 2.5.8 컬럼과 인덱스 교환하기
transpose() 또는 T 사용
# 2.6 데이터 인덱싱(데이터프레임의 값 선택)
## 2.6.1 문자형 인덱스 인덱싱하기
```python
df.loc['인덱스명']
df.loc[df['컬럼명'] > 40]] # 컬럼의 값 중 40 이상인 값만 추출
df.loc[] = 50 # 값 변경
```
## 2.6.2 위치 기반 인덱싱하기
```python
df.iloc[[0]]
```
## 2.6.3 컬럼을 익덱스로 만들기, 재정의하기
```python
df.reset_index(inplace=True)
```
